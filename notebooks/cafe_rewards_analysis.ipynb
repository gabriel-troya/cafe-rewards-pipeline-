{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7cbb96a-bf73-4932-b633-70ad803ee56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offers Schema:\n",
      "root\n",
      " |-- offer_id: string (nullable = true)\n",
      " |-- offer_type: string (nullable = true)\n",
      " |-- difficulty: integer (nullable = true)\n",
      " |-- reward: integer (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- channels: string (nullable = true)\n",
      "\n",
      "\n",
      "Offers Sample Data:\n",
      "+--------------------+-------------+----------+------+--------+--------------------+\n",
      "|            offer_id|   offer_type|difficulty|reward|duration|            channels|\n",
      "+--------------------+-------------+----------+------+--------+--------------------+\n",
      "|ae264e3637204a6fb...|         bogo|        10|    10|       7|['email', 'mobile...|\n",
      "|4d5c57ea9a6940dd8...|         bogo|        10|    10|       5|['web', 'email', ...|\n",
      "|3f207df678b143eea...|informational|         0|     0|       4|['web', 'email', ...|\n",
      "|9b98b8c7a33c4b65b...|         bogo|         5|     5|       7|['web', 'email', ...|\n",
      "|0b1e1539f2cc45b7b...|     discount|        20|     5|      10|    ['web', 'email']|\n",
      "+--------------------+-------------+----------+------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Customers Schema:\n",
      "root\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- became_member_on: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- income: integer (nullable = true)\n",
      "\n",
      "\n",
      "Customers Sample Data:\n",
      "+--------------------+----------------+------+---+------+\n",
      "|         customer_id|became_member_on|gender|age|income|\n",
      "+--------------------+----------------+------+---+------+\n",
      "|68be06ca386d4c319...|        20170212|  null|118|  null|\n",
      "|0610b486422d4921a...|        20170715|     F| 55|112000|\n",
      "|38fe809add3b4fcf9...|        20180712|  null|118|  null|\n",
      "|78afa995795e4d85b...|        20170509|     F| 75|100000|\n",
      "|a03223e636434f42a...|        20170804|  null|118|  null|\n",
      "+--------------------+----------------+------+---+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Events Schema:\n",
      "root\n",
      " |-- customer_id;event;value;time: string (nullable = true)\n",
      "\n",
      "\n",
      "Events Sample Data:\n",
      "+----------------------------+\n",
      "|customer_id;event;value;time|\n",
      "+----------------------------+\n",
      "|        78afa995795e4d85b...|\n",
      "|        a03223e636434f42a...|\n",
      "|        e2127556f4f64592b...|\n",
      "|        8ec6ce2a7e7949b1b...|\n",
      "|        68617ca6246f4fbc8...|\n",
      "+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Basic Statistics:\n",
      "Number of offers: 10\n",
      "Number of customers: 17000\n",
      "Number of events: 290319\n",
      "\n",
      "Cleaned Offers Data:\n",
      "+--------------------+-------------+----------+------+--------+--------------------+\n",
      "|            offer_id|   offer_type|difficulty|reward|duration|            channels|\n",
      "+--------------------+-------------+----------+------+--------+--------------------+\n",
      "|0b1e1539f2cc45b7b...|     discount|        20|     5|      10|    ['web', 'email']|\n",
      "|2298d6c36e964ae4a...|     discount|         7|     3|       7|['web', 'email', ...|\n",
      "|2906b810c7d441179...|     discount|        10|     2|       7|['web', 'email', ...|\n",
      "|3f207df678b143eea...|informational|         0|     0|       4|['web', 'email', ...|\n",
      "|4d5c57ea9a6940dd8...|         bogo|        10|    10|       5|['web', 'email', ...|\n",
      "+--------------------+-------------+----------+------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Cleaned Customers Data:\n",
      "+--------------------+----------------+------+---+------+---------+\n",
      "|         customer_id|became_member_on|gender|age|income|age_group|\n",
      "+--------------------+----------------+------+---+------+---------+\n",
      "|0009655768c64bdeb...|        20170421|     M| 33| 72000|    30-39|\n",
      "|0011e0d4e6b944f99...|        20180109|     O| 40| 57000|    40-49|\n",
      "|0020c2b971eb4e918...|        20160304|     F| 59| 90000|    50-59|\n",
      "|0020ccbbb6d84e358...|        20161111|     F| 24| 60000|    20-29|\n",
      "|003d66b6608740288...|        20170621|     F| 26| 73000|    20-29|\n",
      "+--------------------+----------------+------+---+------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Cleaned Events Data:\n",
      "+----------------------------+\n",
      "|customer_id;event;value;time|\n",
      "+----------------------------+\n",
      "|        78afa995795e4d85b...|\n",
      "|        a03223e636434f42a...|\n",
      "|        e2127556f4f64592b...|\n",
      "|        8ec6ce2a7e7949b1b...|\n",
      "|        68617ca6246f4fbc8...|\n",
      "+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `customer_id;event;value;time` cannot be resolved on the right side of the join. The right-side columns: [`channels`, `difficulty`, `duration`, `offer_id`, `offer_type`, `reward`].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 258\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m journey\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# Create the offer journey dataset\u001b[39;00m\n\u001b[1;32m--> 258\u001b[0m offer_journey \u001b[38;5;241m=\u001b[39m create_offer_journey(trusted_events, trusted_offers, trusted_customers)\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOffer Journey Dataset:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    260\u001b[0m offer_journey\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[1;32mIn[31], line 242\u001b[0m, in \u001b[0;36mcreate_offer_journey\u001b[1;34m(events_df, offers_df, customers_df)\u001b[0m\n\u001b[0;32m    236\u001b[0m journey \u001b[38;5;241m=\u001b[39m journey\u001b[38;5;241m.\u001b[39mwithColumn(\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_completed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    238\u001b[0m     F\u001b[38;5;241m.\u001b[39mwhen(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleted_time\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39misNotNull(), \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39motherwise(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    239\u001b[0m )\n\u001b[0;32m    241\u001b[0m \u001b[38;5;66;03m# Join with offers to get offer details\u001b[39;00m\n\u001b[1;32m--> 242\u001b[0m journey \u001b[38;5;241m=\u001b[39m journey\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    243\u001b[0m     offers_df,\n\u001b[0;32m    244\u001b[0m     offer_col,\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m )\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# Join with customers to get customer details\u001b[39;00m\n\u001b[0;32m    249\u001b[0m journey \u001b[38;5;241m=\u001b[39m journey\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    250\u001b[0m     customers_df,\n\u001b[0;32m    251\u001b[0m     cust_col,\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m )\n",
      "File \u001b[1;32mD:\\Python\\anaconda3\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:2344\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[1;34m(self, other, on, how)\u001b[0m\n\u001b[0;32m   2342\u001b[0m         on \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jseq([])\n\u001b[0;32m   2343\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(how, \u001b[38;5;28mstr\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhow should be a string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2344\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mjoin(other\u001b[38;5;241m.\u001b[39m_jdf, on, how)\n\u001b[0;32m   2345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[1;32mD:\\Python\\anaconda3\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mD:\\Python\\anaconda3\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    171\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: [UNRESOLVED_USING_COLUMN_FOR_JOIN] USING column `customer_id;event;value;time` cannot be resolved on the right side of the join. The right-side columns: [`channels`, `difficulty`, `duration`, `offer_id`, `offer_type`, `reward`]."
     ]
    }
   ],
   "source": [
    "# Caf√© Rewards Data Pipeline and Analysis\n",
    "\n",
    "## 1. Setup and Initialization\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# PySpark imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Cafe Rewards Analysis\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "## 2. Raw Layer - Data Ingestion\n",
    "\n",
    "### 2.1 Load Datasets\n",
    "\n",
    "# Define paths to data files\n",
    "data_dir = \"data/raw\"\n",
    "offers_path = os.path.join(data_dir, \"offers.csv\")\n",
    "customers_path = os.path.join(data_dir, \"customers.csv\")\n",
    "events_path = os.path.join(data_dir, \"events.csv\")\n",
    "\n",
    "# Load datasets\n",
    "offers_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(offers_path)\n",
    "customers_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(customers_path)\n",
    "events_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(events_path)\n",
    "\n",
    "\n",
    "### 2.2 Explore Raw Data\n",
    "\n",
    "# Display schema and sample data\n",
    "print(\"Offers Schema:\")\n",
    "offers_df.printSchema()\n",
    "print(\"\\nOffers Sample Data:\")\n",
    "offers_df.show(5)\n",
    "\n",
    "print(\"\\nCustomers Schema:\")\n",
    "customers_df.printSchema()\n",
    "print(\"\\nCustomers Sample Data:\")\n",
    "customers_df.show(5)\n",
    "\n",
    "print(\"\\nEvents Schema:\")\n",
    "events_df.printSchema()\n",
    "print(\"\\nEvents Sample Data:\")\n",
    "events_df.show(5)\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(f\"Number of offers: {offers_df.count()}\")\n",
    "print(f\"Number of customers: {customers_df.count()}\")\n",
    "print(f\"Number of events: {events_df.count()}\")\n",
    "\n",
    "## 3. Trusted Layer - Data Cleaning and Transformation\n",
    "\n",
    "### 3.1 Clean Offers Data\n",
    "\n",
    "\n",
    "# Clean offers data\n",
    "def clean_offers(df):\n",
    "    # Drop duplicates\n",
    "    cleaned_df = df.dropDuplicates([\"offer_id\"])\n",
    "    \n",
    "    return cleaned_df\n",
    "\n",
    "trusted_offers = clean_offers(offers_df)\n",
    "print(\"\\nCleaned Offers Data:\")\n",
    "trusted_offers.show(5)\n",
    "\n",
    "\n",
    "### 3.2 Clean Customers Data\n",
    "\n",
    "\n",
    "# Clean customers data\n",
    "def clean_customers(df):\n",
    "    # Drop duplicates\n",
    "    cleaned_df = df.dropDuplicates([\"customer_id\"])\n",
    "    \n",
    "    # Handle missing values\n",
    "    cleaned_df = cleaned_df.na.drop()\n",
    "    \n",
    "    # Calculate age from birth year (assuming current year is 2025)\n",
    "    if \"birthYear\" in df.columns:\n",
    "        current_year = 2025\n",
    "        cleaned_df = cleaned_df.withColumn(\"age\", F.lit(current_year) - F.col(\"birthYear\"))\n",
    "    \n",
    "    # Create age groups\n",
    "    cleaned_df = cleaned_df.withColumn(\n",
    "        \"age_group\",\n",
    "        F.when(F.col(\"age\") < 20, \"Under 20\")\n",
    "         .when(F.col(\"age\").between(20, 29), \"20-29\")\n",
    "         .when(F.col(\"age\").between(30, 39), \"30-39\")\n",
    "         .when(F.col(\"age\").between(40, 49), \"40-49\")\n",
    "         .when(F.col(\"age\").between(50, 59), \"50-59\")\n",
    "         .otherwise(\"60+\")\n",
    "    )\n",
    "    \n",
    "    return cleaned_df\n",
    "\n",
    "trusted_customers = clean_customers(customers_df)\n",
    "print(\"\\nCleaned Customers Data:\")\n",
    "trusted_customers.show(5)\n",
    "\n",
    "\n",
    "### 3.3 Clean Events Data\n",
    "\n",
    "\n",
    "# Clean events data\n",
    "def clean_events(df):\n",
    "    \n",
    "    cleaned_df = df\n",
    "    \n",
    "    if \"timestamp\" in df.columns:\n",
    "        cleaned_df = cleaned_df.withColumn(\n",
    "            \"timestamp\", \n",
    "            F.to_timestamp(F.col(\"timestamp\"))\n",
    "        )\n",
    "    \n",
    "    return cleaned_df\n",
    "\n",
    "trusted_events = clean_events(events_df)\n",
    "print(\"\\nCleaned Events Data:\")\n",
    "trusted_events.show(5)\n",
    "\n",
    "\n",
    "### 3.4 Save Trusted Data\n",
    "\n",
    "\n",
    "# Save trusted data \n",
    "#trusted_dir = \"data/trusted\"\n",
    "#trusted_dir = \"C:\\\\Users\\\\gabri\\\\Jupyter\\\\data\\\\trusted\"\n",
    "#os.makedirs(trusted_dir, exist_ok=True)\n",
    "\n",
    "#trusted_offers.write.mode(\"overwrite\").parquet(os.path.join(trusted_dir, \"offers\"))\n",
    "#trusted_customers.write.mode(\"overwrite\").parquet(os.path.join(trusted_dir, \"customers\"))\n",
    "#trusted_events.write.mode(\"overwrite\").parquet(os.path.join(trusted_dir, \"events\"))\n",
    "\n",
    "\n",
    "## 4. Refined Layer - Data Enrichment and Aggregation\n",
    "\n",
    "### 4.1 Create Offer Journey Dataset\n",
    "\n",
    "\n",
    "# Create a dataset that captures the full journey of an offer\n",
    "def create_offer_journey(events_df, offers_df, customers_df):\n",
    "    # Filter events by type\n",
    "\n",
    "    event_col = \"event\" if \"event\" in events_df.columns else None\n",
    "    if not event_col:\n",
    "        # Try to find a column that might contain event types\n",
    "        event_candidates = [col for col in events_df.columns if \"event\" in col.lower() or \"type\" in col.lower()]\n",
    "        event_col = event_candidates[0] if event_candidates else None\n",
    "    \n",
    "    if not event_col:\n",
    "        raise ValueError(\"Could not find event type column in events dataframe\")\n",
    "\n",
    "    cust_col = next((col for col in events_df.columns if \"customer_id\" in col.lower()), None)\n",
    "    if not cust_col:\n",
    "        raise ValueError(\"Could not find customer ID column in events dataframe\")\n",
    "\n",
    "    offer_col = next((col for col in events_df.columns if \"value\" in col.lower()), None)\n",
    "    if not offer_col:\n",
    "        raise ValueError(\"Could not find offer ID column in events dataframe\")\n",
    "\n",
    "    time_col = next((col for col in events_df.columns if \"time\" in col.lower()), None)\n",
    "    if not time_col:\n",
    "        raise ValueError(\"Could not find timestamp column in events dataframe\")\n",
    "\n",
    "    \n",
    "    received_offers = events_df.filter(F.lower(F.col(event_col)).like(\"%receive%\"))\n",
    "    viewed_offers = events_df.filter(F.lower(F.col(event_col)).like(\"%view%\"))\n",
    "    completed_offers = events_df.filter(F.lower(F.col(event_col)).like(\"%complete%\"))\n",
    "    \n",
    "    # Join the different event types to create a journey\n",
    "    journey = received_offers.select(\n",
    "        F.col(cust_col),\n",
    "        F.col(offer_col),\n",
    "        F.col(time_col).alias(\"received_time\")\n",
    "    )\n",
    "    \n",
    "    # Left join with viewed events\n",
    "    journey = journey.join(\n",
    "        viewed_offers.select(\n",
    "            F.col(cust_col),\n",
    "            F.col(offer_col),\n",
    "            F.col(time_col).alias(\"viewed_time\")\n",
    "        ),\n",
    "        [cust_col, offer_col],\n",
    "        \"left\"\n",
    "    )\n",
    "    \n",
    "    # Left join with completed events\n",
    "    journey = journey.join(\n",
    "        completed_offers.select(\n",
    "            F.col(cust_col),\n",
    "            F.col(offer_col),\n",
    "            F.col(time_col).alias(\"completed_time\")\n",
    "        ),\n",
    "        [cust_col, offer_col],\n",
    "        \"left\"\n",
    "    )\n",
    "    \n",
    "    # Calculate time differences\n",
    "    journey = journey.withColumn(\n",
    "        \"time_to_view_hours\",\n",
    "        F.when(F.col(\"viewed_time\").isNotNull(),\n",
    "               (F.unix_timestamp(\"viewed_time\") - F.unix_timestamp(\"received_time\")) / 3600)\n",
    "        .otherwise(None)\n",
    "    )\n",
    "    \n",
    "    journey = journey.withColumn(\n",
    "        \"time_to_complete_hours\",\n",
    "        F.when(F.col(\"completed_time\").isNotNull(),\n",
    "               (F.unix_timestamp(\"completed_time\") - F.unix_timestamp(\"received_time\")) / 3600)\n",
    "        .otherwise(None)\n",
    "    )\n",
    "    \n",
    "    # Add completion flag\n",
    "    journey = journey.withColumn(\n",
    "        \"is_completed\",\n",
    "        F.when(F.col(\"completed_time\").isNotNull(), 1).otherwise(0)\n",
    "    )\n",
    "    \n",
    "    # Join with offers to get offer details\n",
    "    journey = journey.join(\n",
    "        offers_df,\n",
    "        offer_col,\n",
    "        \"inner\"\n",
    "    )\n",
    "    \n",
    "    # Join with customers to get customer details\n",
    "    journey = journey.join(\n",
    "        customers_df,\n",
    "        cust_col,\n",
    "        \"inner\"\n",
    "    )\n",
    "    \n",
    "    return journey\n",
    "\n",
    "# Create the offer journey dataset\n",
    "offer_journey = create_offer_journey(trusted_events, trusted_offers, trusted_customers)\n",
    "print(\"\\nOffer Journey Dataset:\")\n",
    "offer_journey.show(5)\n",
    "\n",
    "\n",
    "### 4.2 Create Marketing Channel Metrics\n",
    "\n",
    "\n",
    "# Analyze marketing channel effectiveness\n",
    "def analyze_channel_effectiveness(journey_df):\n",
    "    channel_metrics = journey_df.groupBy(\"channel\").agg(\n",
    "        F.count(\"offer_id\").alias(\"total_offers\"),\n",
    "        F.sum(\"is_completed\").alias(\"completed_offers\"),\n",
    "        (F.sum(\"is_completed\") / F.count(\"offer_id\") * 100).alias(\"completion_rate\")\n",
    "    ).orderBy(F.desc(\"completion_rate\"))\n",
    "    \n",
    "    return channel_metrics\n",
    "\n",
    "channel_metrics = analyze_channel_effectiveness(offer_journey)\n",
    "print(\"\\nMarketing Channel Effectiveness:\")\n",
    "channel_metrics.show()\n",
    "\n",
    "\n",
    "### 4.3 Create Age Distribution Metrics\n",
    "\n",
    "\n",
    "# Analyze age distribution of offer completion\n",
    "def analyze_age_distribution(journey_df):\n",
    "    age_metrics = journey_df.groupBy(\"age_group\").agg(\n",
    "        F.count(\"offer_id\").alias(\"total_offers\"),\n",
    "        F.sum(\"is_completed\").alias(\"completed_offers\"),\n",
    "        (F.sum(\"is_completed\") / F.count(\"offer_id\") * 100).alias(\"completion_rate\"),\n",
    "        F.count(F.when(F.col(\"is_completed\") == 0, 1)).alias(\"not_completed_offers\")\n",
    "    ).orderBy(\"age_group\")\n",
    "    \n",
    "    return age_metrics\n",
    "\n",
    "age_metrics = analyze_age_distribution(offer_journey)\n",
    "print(\"\\nAge Distribution of Offer Completion:\")\n",
    "age_metrics.show()\n",
    "\n",
    "# Visualize the age distribution\n",
    "age_pandas = age_metrics.toPandas()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "x = age_pandas['age_group']\n",
    "y1 = age_pandas['completed_offers']\n",
    "y2 = age_pandas['not_completed_offers']\n",
    "\n",
    "plt.bar(x, y1, color='green', label='Completed Offers')\n",
    "plt.bar(x, y2, bottom=y1, color='red', label='Not Completed Offers')\n",
    "\n",
    "plt.title('Offer Completion by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Number of Offers')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot completion rate by age group\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(age_pandas['age_group'], age_pandas['completion_rate'], color='blue')\n",
    "plt.title('Offer Completion Rate by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Completion Rate (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### 4.4 Analyze Time to Completion\n",
    "\n",
    "# Analyze the average time taken to complete offers\n",
    "def analyze_completion_time(journey_df):\n",
    "    # Filter for completed offers only\n",
    "    completed_df = journey_df.filter(F.col(\"is_completed\") == 1)\n",
    "    \n",
    "    # Calculate average time to completion\n",
    "    avg_time = completed_df.agg(\n",
    "        F.avg(\"time_to_complete_hours\").alias(\"avg_hours\"),\n",
    "        F.stddev(\"time_to_complete_hours\").alias(\"stddev_hours\"),\n",
    "        F.min(\"time_to_complete_hours\").alias(\"min_hours\"),\n",
    "        F.max(\"time_to_complete_hours\").alias(\"max_hours\")\n",
    "    )\n",
    "    \n",
    "    # Get distribution of completion times\n",
    "    time_bins = completed_df.withColumn(\n",
    "        \"hour_bin\", \n",
    "        F.floor(F.col(\"time_to_complete_hours\") / 6) * 6\n",
    "    ).groupBy(\"hour_bin\").count().orderBy(\"hour_bin\")\n",
    "    \n",
    "    return avg_time, time_bins\n",
    "\n",
    "avg_time, time_bins = analyze_completion_time(offer_journey)\n",
    "print(\"\\nAverage Time to Completion:\")\n",
    "avg_time.show()\n",
    "\n",
    "# Visualize time to completion\n",
    "time_bins_pd = time_bins.toPandas()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(time_bins_pd['hour_bin'], time_bins_pd['count'], width=5)\n",
    "plt.axvline(x=avg_time.collect()[0]['avg_hours'], color='red', linestyle='--', \n",
    "            label=f\"Average: {avg_time.collect()[0]['avg_hours']:.2f} hours\")\n",
    "plt.title('Distribution of Time to Offer Completion')\n",
    "plt.xlabel('Hours to Complete (binned by 6-hour intervals)')\n",
    "plt.ylabel('Count of Offers')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### 4.5 Save Refined Data\n",
    "\n",
    "# Save refined datasets for future reference\n",
    "refined_dir = \"data/refined\"\n",
    "os.makedirs(refined_dir, exist_ok=True)\n",
    "\n",
    "channel_metrics.write.mode(\"overwrite\").parquet(os.path.join(refined_dir, \"channel_metrics\"))\n",
    "age_metrics.write.mode(\"overwrite\").parquet(os.path.join(refined_dir, \"age_metrics\"))\n",
    "offer_journey.write.mode(\"overwrite\").parquet(os.path.join(refined_dir, \"offer_journey\"))\n",
    "\n",
    "\n",
    "## 5. Answer Analytical Questions\n",
    "\n",
    "### 5.1 Most Effective Marketing Channel\n",
    "\n",
    "# channel_metrics = spark.read.parquet(os.path.join(refined_dir, \"channel_metrics\"))\n",
    "\n",
    "print(\"\\nQuestion 1: Which marketing channel is the most effective in terms of offer completion rate?\")\n",
    "most_effective = channel_metrics.orderBy(F.desc(\"completion_rate\")).first()\n",
    "print(f\"The most effective marketing channel is '{most_effective['channel']}' with a completion rate of {most_effective['completion_rate']:.2f}%\")\n",
    "\n",
    "# Visualize all channels\n",
    "channel_pd = channel_metrics.toPandas()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(channel_pd['channel'], channel_pd['completion_rate'], color='blue')\n",
    "plt.title('Offer Completion Rate by Marketing Channel')\n",
    "plt.xlabel('Channel')\n",
    "plt.ylabel('Completion Rate (%)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### 5.2 Age Distribution Comparison\n",
    "\n",
    "# age_metrics = spark.read.parquet(os.path.join(refined_dir, \"age_metrics\"))\n",
    "\n",
    "print(\"\\nQuestion 2: How is the age distribution of customers who completed offers compared to those who did not?\")\n",
    "print(\"Age distribution metrics:\")\n",
    "age_metrics.show()\n",
    "\n",
    "### 5.3 Average Time to Completion\n",
    "\n",
    "\n",
    "print(\"\\nQuestion 3: What is the average time taken by customers to complete an offer after receiving it?\")\n",
    "avg_hours = avg_time.collect()[0]['avg_hours']\n",
    "print(f\"The average time to complete an offer after receiving it is {avg_hours:.2f} hours (approximately {avg_hours/24:.2f} days)\")\n",
    "\n",
    "\n",
    "\n",
    "# Clean up the Spark session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16a3f75-d3f3-4bf9-bb6a-df73e014995a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
